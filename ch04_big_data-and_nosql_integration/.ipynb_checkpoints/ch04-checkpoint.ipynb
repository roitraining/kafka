{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0358ac4b-aa43-4cc7-bbf4-e5ed6a04d045",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <img src=\"../images/mongo_logo.png\" width=200 height=200 /><font color='cadetblue' size=\"+2\"></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87fb697-f860-428e-8ba3-0a47100dbd1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Let's do a simple test of reading and writing to Mongo-DB to see if it works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3174e5b6-3252-4980-a2c1-76c2da7cdc1a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <img src=\"../images/python_logo.png\" width=50 height=25 /><font size=\"+2\">  This is just basic Mongo-DB directly with Python</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05555ff4-c064-4d6e-ad34-2a28ea981d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install mymongo\n",
    "import pymongo\n",
    "client = pymongo.MongoClient(\"mongodb://127.0.0.1:27017/\")\n",
    "classroom = client[\"classroom\"]\n",
    "if 'classroom' in (x['name'] for x in client.list_databases()):\n",
    "    client.drop_database('classroom')\n",
    "\n",
    "people = classroom['people']\n",
    "name = {\"firstname\" : \"Adam\", \"personid\":4}\n",
    "x = people.insert_one(name)\n",
    "\n",
    "names = [{\"firstname\" : \"Betty\", \"personid\":5}\n",
    "         ,{\"firstname\" : \"Charlie\", \"personid\":6}]\n",
    "x = people.insert_many(names)\n",
    "\n",
    "x = people.find()\n",
    "print ('*' * 80)\n",
    "print ('from mongo directly')\n",
    "print (list(x))\n",
    "print ('*' * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a4f7ab-5172-4f86-9285-ff64035180c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install mymongo\n",
    "import pymongo\n",
    "client = pymongo.MongoClient(\"mongodb://127.0.0.1:27017/\")\n",
    "classroom = client[\"classroom\"]\n",
    "if 'classroom' in (x['name'] for x in client.list_databases()):\n",
    "    client.drop_database('classroom')\n",
    "\n",
    "students = classroom['students']\n",
    "name = {\"studentid\":1, \"firstname\":'Joe', \"lastname\":'Smith', \"emails\": ['joes@xyz.com', 'joe.smith@abc.net']}\n",
    "x = students.insert_one(name)\n",
    "\n",
    "names = [\n",
    "        {\"studentid\":2, \"firstname\":'Mike', \"lastname\":'Jones', \"emails\": ['mikej@xyz.com', 'mike.jones@def.net', 'mike1234@gmail.com']}\n",
    "        , {\"studentid\":3, \"firstname\":'Betty', \"lastname\":'Johnson', \"emails\": ['betty@xyz.com']}\n",
    "]\n",
    "x = students.insert_many(names)\n",
    "\n",
    "x = students.find()\n",
    "print ('*' * 80)\n",
    "print ('from mongo directly')\n",
    "for s in x:\n",
    "    print(s)\n",
    "print ('*' * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bffe3a-8a0d-42c6-bb28-1b6e24c5d3d5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## <img src=\"../images/spark_logo.png\" width=100 height=50 /><font size=\"+2\">  This uses the Spark Cassandra connector to read and write between a Spark DataFrame and Cassandra</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06f6f68-57e9-4c0c-b342-ba531b461f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install cassandra-driver\n",
    "# pyspark --packages com.datastax.spark:spark-cassandra-connector_2.12:3.0.1\n",
    "\n",
    "import os\n",
    "from cassandra.cluster import Cluster\n",
    "from cassandra.auth import PlainTextAuthProvider\n",
    "\n",
    "#CASSANDRA_HOST = 'localhost'\n",
    "CASSANDRA_HOST = '127.0.0.1'\n",
    "CASSANDRA_USER = 'cassandra'\n",
    "CASSANDRA_PASSWORD = 'student'\n",
    "\n",
    "ap = PlainTextAuthProvider(username=CASSANDRA_USER, password=CASSANDRA_PASSWORD)\n",
    "cluster = Cluster([CASSANDRA_HOST], auth_provider = ap)\n",
    "cluster.connect()\n",
    "\n",
    "import sys\n",
    "sys.path.append('/class')\n",
    "os.environ['PYSPARK_PYTHON'] = '/usr/bin/python3'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = '/usr/bin/python3'\n",
    "sys.path.append('/class')\n",
    "if 'sc' in locals():\n",
    "    sc.stop()\n",
    "\n",
    "if 'sc' not in locals():\n",
    "    from initspark import initspark\n",
    "    sc, spark, conf = initspark(mongo=\"mongodb://127.0.0.1/classroom\", packages = ['mongo'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bc8ca6-3c1a-4958-9c4c-2bf8f430fc9d",
   "metadata": {},
   "source": [
    "### First read what's already there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62716d64-1e9c-46e6-9dd9-ac228a5fe3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"mongo\").option(\"uri\", \"mongodb://127.0.0.1/classroom.students\").load()\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f705cff-4894-491c-8018-de8e1bdd2da6",
   "metadata": {},
   "source": [
    "### Add a new document from a Spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828bd881-a7a9-4911-9be0-daa99b64bdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sc.parallelize([(4, 'Han', 'Solo', ['han@starwars.com'])])\n",
    "x1 = spark.createDataFrame(x, schema = ['studentid', 'firstname', 'lastname', 'emails'])\n",
    "x1.write.format(\"mongo\").option(\"uri\", \"mongodb://127.0.0.1/classroom.students\").mode(\"append\").save()\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7160cd-0e55-4d38-8b93-a2421ac3897d",
   "metadata": {},
   "source": [
    "### Confirm that it worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d29aff8-b069-4a9b-b1db-d745581056c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"mongo\").option(\"uri\", \"mongodb://127.0.0.1/classroom.students\").load()\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d22e2a-bb8f-4fc7-8535-03a2861051f8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## <img src=\"../images/beam_logo.png\" width=100 height=50 /><font size=\"+2\">The MongoDB connectors for Beam are pretty straight forward.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69b3791-9b69-4677-9155-9ffb928cba69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromMongoDB\n",
    "connection_string = 'mongodb://localhost:27017'\n",
    "with beam.Pipeline() as p:\n",
    "    (p\n",
    "     | 'read' >> ReadFromMongoDB(connection_string, 'classroom', 'students') \n",
    "     | 'print' >> beam.Map(print)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b029daa-aa07-4960-b9ea-a077d30e0c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromMongoDB, WriteToMongoDB\n",
    "connection_string = 'mongodb://localhost:27017'\n",
    "with beam.Pipeline() as p:\n",
    "    (p\n",
    "     | 'create' >> beam.Create([{\"studentid\":5, \"firstname\": \"Luke\", \"lastname\":\"Skywalker\", \"personid\":5, \"emails\":[\"luke@tattoine.com\",\"luke@jedi.org\"]}])\n",
    "     | 'write' >> WriteToMongoDB(connection_string, 'classroom', 'students') \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35c6e18-bda6-4c68-9133-aa715caffb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromMongoDB\n",
    "connection_string = 'mongodb://localhost:27017'\n",
    "with beam.Pipeline() as p:\n",
    "    (p\n",
    "     | 'read' >> ReadFromMongoDB(connection_string, 'classroom', 'students', filter = {\"firstname\":\"Luke\"}, projection= {\"firstname\": 1, \"lastname\":1}) \n",
    "     | 'print' >> beam.Map(print)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcfac27-a782-405f-bf1c-6c4582069456",
   "metadata": {},
   "source": [
    "# __ __ __ __ __ __ __ __ __ __ __ __"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da4cc82",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <img src=\"../images/cassandra_logo.png\" width=100 height=50 /><font color='cadetblue' size=\"+2\"></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1361d6-cd85-49b8-8d35-357baac8bb69",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Let's do a simple test of reading and writing to Cassandra to see if it works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6902b1-1a90-4850-a5db-5256f6fdce22",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <img src=\"../images/python_logo.png\" width=50 height=25 /><font size=\"+2\">  This is just basic Cassandra example using Python directly</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24670d81-a052-4e0e-8307-01a1f4c199b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "session = cluster.connect()\n",
    "session.execute('DROP KEYSPACE IF EXISTS classroom')\n",
    "session.execute(\"CREATE KEYSPACE classroom WITH REPLICATION={'class':'SimpleStrategy', 'replication_factor':'1'}\")\n",
    "session = cluster.connect('classroom')\n",
    "session.execute(\"create table student(id int PRIMARY KEY, firstname text, lastname text, emails set<text>)\")\n",
    "session.execute(\"insert into student (id, firstname, lastname, emails) values (1, 'Joe', 'Smith', {'joes@xyz.com', 'joe.smith@abc.net'})\")\n",
    "session.execute(\"update student set firstname = 'Joseph' where id = 1\")\n",
    "session.execute(\"insert into student (id, firstname, lastname, emails) values (2, 'Mike', 'Jones', {'mikej@xyz.com', 'mike.jones@def.net', 'mike1234@gmail.com'})\")\n",
    "rows = session.execute('SELECT id, firstname, lastname, emails from student')\n",
    "print('*' * 80)\n",
    "print('student rows from cassandra directly')\n",
    "print('*' * 80)\n",
    "print(list(rows))\n",
    "print('*' * 80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cffc88-bcf5-4875-a7c9-9a25e84694cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <img src=\"../images/spark_logo.png\" width=100 height=50 /><font size=\"+2\">  This uses the Spark Cassandra connector to read and write between a Spark DataFrame and Cassandra</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73db6eb7-af43-4418-94d0-9f810ebe3fe9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Set up the spark context but remember to add the package for Cassandra and any others needed. The initspark.py helper function provided shows examples of how to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c99f49-50cc-4a8c-b8bf-3d0a68e7a89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install cassandra-driver\n",
    "# pyspark --packages com.datastax.spark:spark-cassandra-connector_2.12:3.0.0\n",
    "import os\n",
    "from cassandra.cluster import Cluster\n",
    "from cassandra.auth import PlainTextAuthProvider\n",
    "\n",
    "#CASSANDRA_HOST = 'localhost'\n",
    "CASSANDRA_HOST = '127.0.0.1'\n",
    "CASSANDRA_USER = 'cassandra'\n",
    "CASSANDRA_PASSWORD = 'student'\n",
    "\n",
    "ap = PlainTextAuthProvider(username=CASSANDRA_USER, password=CASSANDRA_PASSWORD)\n",
    "cluster = Cluster([CASSANDRA_HOST], auth_provider = ap)\n",
    "cluster.connect()\n",
    "\n",
    "import sys\n",
    "sys.path.append('/class')\n",
    "os.environ['PYSPARK_PYTHON'] = '/usr/bin/python3'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = '/usr/bin/python3'\n",
    "sys.path.append('/class')\n",
    "\n",
    "if 'sc' in locals():\n",
    "    sc.stop()\n",
    "    \n",
    "from initspark import initspark\n",
    "sc, spark, conf = initspark(cassandra = \"127.0.0.1\", cassandra_user = 'cassandra'\n",
    "                            , cassandra_password='student', packages = ['cassandra'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea86b49-76c7-4c44-97ff-9983e58bd9b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Use standard Spark read and write methods using the right package for Cassandra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181776f0-d3ba-42f5-b7d8-5342fd293da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python to access a Cassandra cluster through Spark\n",
    "people = spark.read.format(\"org.apache.spark.sql.cassandra\").options(table=\"student\", keyspace=\"classroom\").load()\n",
    "print('*' * 80)\n",
    "print('student rows from spark before insert')\n",
    "print('*' * 80)\n",
    "people.show()\n",
    "print(people.collect())\n",
    "print('*' * 80)\n",
    "\n",
    "# Append the results of a DataFrame into a Cassandra table\n",
    "x = sc.parallelize([(3, 'Mary', 'Johnson', ['Mary1@gmail.com', 'Mary2@yahoo.com'])])\n",
    "x1 = spark.createDataFrame(x, schema = ['id', 'firstname', 'lastname', 'emails'])\n",
    "x1.write.format(\"org.apache.spark.sql.cassandra\").options(table=\"student\", keyspace=\"classroom\").mode(\"append\").save()\n",
    "\n",
    "people = spark.read.format(\"org.apache.spark.sql.cassandra\").options(table=\"student\", keyspace=\"classroom\").load()\n",
    "print('*' * 80)\n",
    "print('student rows from spark after insert')\n",
    "print('*' * 80)\n",
    "people.show()\n",
    "print(people.collect())\n",
    "print('*' * 80)\n",
    "\n",
    "print('*' * 80)\n",
    "print('spark sql query from cassandra')\n",
    "print('*' * 80)\n",
    "people.createOrReplaceTempView('people')\n",
    "people2 = spark.sql('select id, firstname, lastname, email from people LATERAL VIEW EXPLODE(emails) EXPLODED_TABLE AS email')\n",
    "people2.show()\n",
    "\n",
    "people3 = people2.where(\"email like '%.com'\").orderBy(\"id\")\n",
    "people3.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283bcaf1-9b0d-4acf-9a8b-38d58f822809",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## <img src=\"../images/beam_logo.png\" width=100 height=50 /><font size=\"+2\">  Currently Beam CassandraIO is only supported on Java</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86498a83-db7d-4117-866d-e46b9b4bfbaf",
   "metadata": {},
   "source": [
    "### Refer here for a list of supported connectors: https://beam.apache.org/documentation/io/built-in/. It's only a matter of time before this is supported on Python. Below is a sample of Java code showing reading and writing PCollections in a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309ed6a6-7622-4e24-a02a-da44812a36ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Java example of reading from Apache Cassandra\n",
    "\n",
    "pipeline.apply(CassandraIO.<Person>read()\n",
    "     .withHosts(Arrays.asList(\"host1\", \"host2\"))\n",
    "     .withPort(9042)\n",
    "     .withKeyspace(\"beam\")\n",
    "     .withTable(\"Person\")\n",
    "     .withEntity(Person.class)\n",
    "     .withCoder(SerializableCoder.of(Person.class))\n",
    "\n",
    " \n",
    "// Java example of writing to Apache Cassandra\n",
    "\n",
    " pipeline\n",
    "    .apply(...) // provides a PCollection<Person> where Person is an entity\n",
    "    .apply(CassandraIO.<Person>write()\n",
    "        .withHosts(Arrays.asList(\"host1\", \"host2\"))\n",
    "        .withPort(9042)\n",
    "        .withKeyspace(\"beam\")\n",
    "        .withEntity(Person.class));\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cd7bb0-1d12-4dde-ae6d-aab010c7440d",
   "metadata": {},
   "source": [
    "# __ __ __ __ __ __ __ __ __ __ __ __"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ca36f2-5da1-4889-9a7b-e9c4bf8ec15d",
   "metadata": {},
   "source": [
    "# <img src=\"../images/hbase_logo.png\" width=200 height=200 /><font color='cadetblue' size=\"+2\"></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a849afe-60ba-401b-81b8-342a5e92659d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append('/class')\n",
    "os.environ['PYSPARK_PYTHON'] = '/usr/bin/python3'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = '/usr/bin/python3'\n",
    "os.environ['\n",
    "sys.path.append('/class')\n",
    "if 'sc' in locals():\n",
    "    sc.stop()\n",
    "\n",
    "if 'sc' not in locals():\n",
    "    from initspark import initspark\n",
    "    sc, spark, conf = initspark(packages = ['hbase'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5163e6-e8f3-40a4-8505-6a2d3780a5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source_format = 'org.apache.hadoop.hbase.spark'\n",
    "df = sc.parallelize([('a', '1.0'), ('b', '2.0')]).toDF(schema=['col0', 'col1'])\n",
    "\n",
    "# ''.join(string.split()) in order to write a multi-line JSON string here.\n",
    "catalog = ''.join(\"\"\"{\n",
    "    \"table\":{\"namespace\":\"default\", \"name\":\"testtable\"},\n",
    "    \"rowkey\":\"key\",\n",
    "    \"columns\":{\n",
    "        \"col0\":{\"cf\":\"rowkey\", \"col\":\"key\", \"type\":\"string\"},\n",
    "        \"col1\":{\"cf\":\"cf\", \"col\":\"col1\", \"type\":\"string\"}\n",
    "    }\n",
    "}\"\"\".split())\n",
    "\n",
    "\n",
    "# Writing\n",
    "df.write.options(catalog=catalog).format(data_source_format).save()\n",
    "\n",
    "# Reading\n",
    "df = sqlc.read.options(catalog=catalog).format(data_source_format).load()\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0a1caf-1a19-47b4-94be-cfdfaf2d65d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
